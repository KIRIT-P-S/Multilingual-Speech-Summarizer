{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0312c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955f1d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e6292",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_model = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"distil-whisper/distil-large-v3\",\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea167d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"facebook/bart-large-cnn\",\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d70855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = asr_model(audio)[\"text\"]\n",
    "    \n",
    "print(f\"Transcription length: {len(transcription.split())} words\")\n",
    "    \n",
    "if len(transcription.split()) < 30:\n",
    "    summary = \"Text too short for summarization. Full transcription shown below.\"\n",
    "else:\n",
    "    print(\"Generating summary...\")\n",
    "    summary_result = summarizer(\n",
    "        transcription,\n",
    "        max_length=150,\n",
    "        min_length=40,\n",
    "        do_sample=False\n",
    "    )\n",
    "    summary = summary_result[0][\"summary_text\"]\n",
    "print(transcription, summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b8619-17bd-4d42-a244-77cb88de4643",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(title=\"Multilingual Speech Summarizer\") as demo:\n",
    "    gr.Markdown(\"# Multilingual Speech Summarizer\")\n",
    "    gr.Markdown(\"**Speak or upload audio in any language** - Auto-detects language and generates summaries\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        audio_input = gr.Audio(\n",
    "            sources=[\"microphone\", \"upload\"],\n",
    "            type=\"filepath\",\n",
    "            label=\"Record or Upload Audio (MP3, WAV, M4A supported)\"\n",
    "        )\n",
    "    \n",
    "    with gr.Row():\n",
    "        transcribe_btn = gr.Button(\"Transcribe & Summarize\", variant=\"primary\", size=\"lg\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            transcription_output = gr.Textbox(\n",
    "                label=\"Full Transcription\", \n",
    "                lines=8,\n",
    "                max_lines=10\n",
    "            )\n",
    "        with gr.Column(scale=1):\n",
    "            summary_output = gr.Textbox(\n",
    "                label=\"âœ¨ AI Summary\", \n",
    "                lines=5,\n",
    "                max_lines=8\n",
    "            )\n",
    "    \n",
    "    gr.Examples(\n",
    "        examples=[],\n",
    "        inputs=audio_input\n",
    "    )\n",
    "    \n",
    "    transcribe_btn.click(\n",
    "        fn=process_audio,\n",
    "        inputs=audio_input,\n",
    "        outputs=[transcription_output, summary_output]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorchtensorflow)",
   "language": "python",
   "name": "pytorchtensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
